{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a25261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Zipper</th>\n",
       "      <th>Positioning</th>\n",
       "      <th>Banding</th>\n",
       "      <th>Motion</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Distortion</th>\n",
       "      <th>path</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>dim_x</th>\n",
       "      <th>dim_y</th>\n",
       "      <th>dim_z</th>\n",
       "      <th>spacing_x</th>\n",
       "      <th>spacing_y</th>\n",
       "      <th>spacing_z</th>\n",
       "      <th>view</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_0001_LF_axi.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>LISA_0001</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>146</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>axi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_0001_LF_cor.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>LISA_0001</td>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>cor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename  Noise  Zipper  Positioning  Banding  Motion  \\\n",
       "0  LISA_0001_LF_axi.nii.gz      0       0            0        0       0   \n",
       "1  LISA_0001_LF_cor.nii.gz      0       0            0        0       0   \n",
       "\n",
       "   Contrast  Distortion                                               path  \\\n",
       "0         0           0  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "1         0           0  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "\n",
       "  patient_id  dim_x  dim_y  dim_z  spacing_x  spacing_y  spacing_z view  \n",
       "0  LISA_0001     36    120    146        5.0        1.5        1.5  axi  \n",
       "1  LISA_0001     40    120    120        5.0        1.5        1.5  cor  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src import utils\n",
    "from src.dataset3D import MRIDataset3D\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "utils.set_seed(42)\n",
    "\n",
    "results_dir = '../../results/preprocessed_data/'\n",
    "\n",
    "labels=[\"Noise\", \"Zipper\", \"Positioning\", \"Banding\", \"Motion\", \"Contrast\", \"Distortion\"]\n",
    "LABELS = [\"Noise\",\"Zipper\",\"Positioning\",\"Banding\",\"Motion\",\"Contrast\",\"Distortion\"]\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(results_dir, 'df_train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(results_dir, 'df_test.csv'))\n",
    "df_train[\"patient_id\"] = df_train[\"filename\"].str.extract(r\"(LISA_\\d+)\")\n",
    "df_test[\"patient_id\"]  = df_test[\"filename\"].str.extract(r\"(LISA_VALIDATION_\\d+)\")\n",
    "    \n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98319970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Args para notebooks\n",
    "# =========================\n",
    "class Args:\n",
    "    def __init__(self,\n",
    "                 train_csv,\n",
    "                 test_csv,\n",
    "                 device=\"cuda:5\",\n",
    "                 out_dir=\"./runs_lisa_nb\",\n",
    "                 folds=5,\n",
    "                 epochs=8,\n",
    "                 batch_size=2,\n",
    "                 num_workers=2,\n",
    "                 lr=3e-4,\n",
    "                 wd=1e-4,\n",
    "                 dropout=0.3,\n",
    "                 freeze_n=2,\n",
    "                 spatial_size=(40,120,120),\n",
    "                 use_aug=True,\n",
    "                 seed=42,\n",
    "                 amp=True,\n",
    "                 mode=\"ordinal\",   # \"ordinal\" o \"multiclass\"\n",
    "                 thr1=0.5,         # para ordinal: threshold de y>=1\n",
    "                 thr2=0.5):        # para ordinal: threshold de y==2\n",
    "        self.train_csv = train_csv\n",
    "        self.test_csv  = test_csv\n",
    "        self.out_dir = out_dir\n",
    "        self.device = device\n",
    "        self.folds = folds\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        self.dropout = dropout\n",
    "        self.freeze_n = freeze_n\n",
    "        self.spatial_size = spatial_size\n",
    "        self.use_aug = use_aug\n",
    "        self.seed = seed\n",
    "        self.amp = amp\n",
    "        self.mode = mode\n",
    "        self.thr1 = thr1\n",
    "        self.thr2 = thr2\n",
    "\n",
    "# =========================\n",
    "# 2) Imports y utilidades\n",
    "# =========================\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from torchvision.models.video import r3d_18\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    import random, numpy as np, torch\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def count_pred012(y_pred):\n",
    "    counts = {0:0, 1:0, 2:0}\n",
    "    vals, cnts = np.unique(y_pred, return_counts=True)\n",
    "    for v,c in zip(vals, cnts): counts[int(v)] = int(c)\n",
    "    return counts\n",
    "\n",
    "# =========================\n",
    "# 3) Dataset con target único (por label)\n",
    "#    Reusa tu MRIDataset3D base y selecciona una columna\n",
    "# =========================\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Orientationd, Resized, Spacingd,\n",
    "    ScaleIntensityd, EnsureTyped,\n",
    "    RandFlipd, RandAffined, RandZoomd, Compose\n",
    ")\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from monai.transforms import MapTransform\n",
    "import torch\n",
    "\n",
    "class ReorientToViewAxisd(MapTransform):\n",
    "    \"\"\"\n",
    "    Reordena (C, D, H, W) para alinear 'depth' con la vista deseada sin perder MetaTensor.\n",
    "    Debe aplicarse DESPUÉS de EnsureTyped(track_meta=True), Orientationd y Spacingd,\n",
    "    y ANTES de Resized/ScaleIntensityd.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys, view_axis_getter):\n",
    "        super().__init__(keys)\n",
    "        self.view_axis_getter = view_axis_getter\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        view_axis = self.view_axis_getter(d)\n",
    "\n",
    "        # orden por vista (C, D, H, W) -> (C, newD, newH, newW)\n",
    "        if view_axis == \"sag\":\n",
    "            order = (0, 1, 2, 3)      # D,H,W (igual)\n",
    "        elif view_axis == \"cor\":\n",
    "            order = (0, 2, 1, 3)      # swap D <-> H\n",
    "        elif view_axis == \"axi\":\n",
    "            order = (0, 3, 1, 2)      # W pasa a 'depth'\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid view_axis: {view_axis}\")\n",
    "\n",
    "        for key in self.keys:\n",
    "            img = d[key]\n",
    "            if not isinstance(img, torch.Tensor):\n",
    "                img = torch.as_tensor(img)  # evita numpy -> tensor\n",
    "            # MetaTensor también soporta permute; se mantiene el tipo\n",
    "            d[key] = img.permute(*order).contiguous()\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "class MRIDataset3DOneTarget(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, target_label, is_train=False, use_aug=False, spatial_size=(40,120,120)):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "        self.target_label = target_label\n",
    "        def view_axis_getter(d): return d[\"view_axis\"]\n",
    "        self.view2onehot = {\"axi\": torch.tensor([1,0,0],dtype=torch.float),\n",
    "                            \"cor\": torch.tensor([0,1,0],dtype=torch.float),\n",
    "                            \"sag\": torch.tensor([0,0,1],dtype=torch.float)}\n",
    "        tfms = [\n",
    "            LoadImaged(keys=[\"image\"], image_only=False),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            EnsureTyped(keys=[\"image\"], track_meta=True),      # <- aquí\n",
    "            Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\"], pixdim=(5, 1.5, 1.5), mode=\"bilinear\"),\n",
    "            ReorientToViewAxisd(keys=[\"image\"], view_axis_getter=view_axis_getter),  # <- aquí\n",
    "            Resized(keys=[\"image\"], spatial_size=spatial_size, mode=\"trilinear\"),\n",
    "            ScaleIntensityd(keys=[\"image\"]),\n",
    "        ]\n",
    "\n",
    "        if use_aug:\n",
    "            tfms += [\n",
    "                RandFlipd(keys=[\"image\"], spatial_axis=0, prob=0.3),\n",
    "                RandFlipd(keys=[\"image\"], spatial_axis=1, prob=0.3),\n",
    "                RandAffined(keys=[\"image\"], prob=0.2,\n",
    "                            rotate_range=(0.1,0.1,0.1),\n",
    "                            scale_range=(0.05,0.05,0.05)),\n",
    "                RandZoomd(keys=[\"image\"], min_zoom=0.9, max_zoom=1.1, prob=0.2),\n",
    "            ]\n",
    "        #tfms+=[EnsureTyped(keys=[\"image\"])]\n",
    "        self.transform = Compose(tfms)\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row[\"path\"]\n",
    "        view_axis  = image_path.split(\"_LF_\")[-1].split(\".nii\")[0]\n",
    "        sample = {\"image\": image_path, \"view_axis\": view_axis}\n",
    "        out = self.transform(sample)\n",
    "        image = out[\"image\"]\n",
    "        view_onehot = self.view2onehot[view_axis]\n",
    "        if self.is_train:\n",
    "            y = torch.tensor(int(row[self.target_label]), dtype=torch.long)\n",
    "            return image, y, row[\"filename\"], view_onehot\n",
    "        else:\n",
    "            return image, -1, row[\"filename\"], view_onehot\n",
    "\n",
    "# =========================\n",
    "# 4) Modelo (1 label)\n",
    "# =========================\n",
    "class Model3DResnetOne(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3, pretrained=True, dropout_p=0.3, freeze_n=2, mode=\"ordinal\"):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.backbone = r3d_18(pretrained=pretrained)\n",
    "        self.adapter = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 3, kernel_size=1),\n",
    "        )\n",
    "        # congelar etapas\n",
    "        blocks = [self.backbone.stem, self.backbone.layer1, self.backbone.layer2, self.backbone.layer3, self.backbone.layer4]\n",
    "        for i,b in enumerate(blocks):\n",
    "            req_grad = (i >= freeze_n)\n",
    "            for p in b.parameters(): p.requires_grad = req_grad\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        out_dim = 3 if mode==\"multiclass\" else 2\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_features + 3, in_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_features, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, view_onehot):\n",
    "        x = self.adapter(x)\n",
    "        x = self.backbone.stem(x)\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        x = self.backbone.avgpool(x).flatten(1)\n",
    "        x = torch.cat([x, view_onehot], dim=1)\n",
    "        logits = self.backbone.fc(x)        # (B,3) o (B,2)\n",
    "        return logits\n",
    "\n",
    "# =========================\n",
    "# 5) Folds y loaders\n",
    "# =========================\n",
    "def make_folds(df, n_splits=5):\n",
    "    df = df.copy()\n",
    "    df[\"fold\"] = -1\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    groups = df[\"patient_id\"].values\n",
    "    y_balance = df[LABELS].sum(axis=1).values\n",
    "    for k, (_, val_idx) in enumerate(gkf.split(df, y_balance, groups)):\n",
    "        df.loc[val_idx, \"fold\"] = k\n",
    "    return df\n",
    "\n",
    "def build_loaders_one(df_tr, df_va, target_label, args):\n",
    "    ds_tr = MRIDataset3DOneTarget(df_tr, target_label, is_train=True, use_aug=args.use_aug, spatial_size=args.spatial_size)\n",
    "    ds_va = MRIDataset3DOneTarget(df_va, target_label, is_train=True, use_aug=False,     spatial_size=args.spatial_size)\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=args.batch_size, shuffle=True,  num_workers=args.num_workers, pin_memory=True)\n",
    "    dl_va = DataLoader(ds_va, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
    "    return dl_tr, dl_va\n",
    "\n",
    "# =========================\n",
    "# 6) Entrenamiento por label y fold\n",
    "# =========================\n",
    "def ordinal_decode_one(logits, thr1=0.5, thr2=0.5):\n",
    "    # logits (B,2) -> p_ge1, p_eq2\n",
    "    p = torch.sigmoid(logits)\n",
    "    yhat = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device)\n",
    "    yhat[p[:,0] >= thr1] = 1\n",
    "    yhat[p[:,1] >= thr2] = 2\n",
    "    return yhat, p[:,0], p[:,1]  # (pred, p_ge1, p_eq2)\n",
    "\n",
    "def evaluate_one(model, loader, device, mode, thr1, thr2):\n",
    "    model.eval()\n",
    "    ys, yhats = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y, _, view1h in loader:\n",
    "            imgs, y, view1h = imgs.to(device), y.to(device), view1h.to(device)\n",
    "            logits = model(imgs, view1h)\n",
    "            if mode == \"multiclass\":\n",
    "                pred = logits.argmax(-1)\n",
    "            else:\n",
    "                pred, _, _ = ordinal_decode_one(logits, thr1, thr2)\n",
    "            ys.append(y.cpu().numpy()); yhats.append(pred.cpu().numpy())\n",
    "    y_true = np.concatenate(ys,0); y_pred = np.concatenate(yhats,0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    counts = count_pred012(y_pred)\n",
    "    return f1, acc, counts\n",
    "\n",
    "def train_one_fold_one_label(fold, target_label, df_folds, args, device):\n",
    "    out_dir = os.path.join(args.out_dir, target_label, f\"fold{fold}\")\n",
    "    ensure_dir(out_dir)\n",
    "    df_tr = df_folds[df_folds.fold != fold].reset_index(drop=True)\n",
    "    df_va = df_folds[df_folds.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    dl_tr, dl_va = build_loaders_one(df_tr, df_va, target_label, args)\n",
    "\n",
    "    model = Model3DResnetOne(\n",
    "        in_channels=1, num_classes=3,\n",
    "        pretrained=True, dropout_p=args.dropout,\n",
    "        freeze_n=args.freeze_n, mode=args.mode\n",
    "    ).to(device)\n",
    "\n",
    "    if args.mode == \"multiclass\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                            lr=args.lr, weight_decay=args.wd)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=2, verbose=False)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        pbar = tqdm(dl_tr, desc=f\"[{target_label}] Fold {fold} Epoch {epoch}\")\n",
    "        for imgs, y, _, view1h in pbar:\n",
    "            imgs, y, view1h = imgs.to(device), y.to(device), view1h.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=args.amp):\n",
    "                logits = model(imgs, view1h)  # (B,3) o (B,2)\n",
    "                if args.mode == \"multiclass\":\n",
    "                    loss = F.cross_entropy(logits, y)\n",
    "                else:\n",
    "                    # objetivos ordinales\n",
    "                    t1 = (y >= 1).float()\n",
    "                    t2 = (y == 2).float()\n",
    "                    loss = criterion(logits[:,0], t1) + criterion(logits[:,1], t2)\n",
    "                    loss = loss / 2.0\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=f\"{np.mean(losses):.4f}\")\n",
    "\n",
    "        f1, acc, counts = evaluate_one(model, dl_va, device, args.mode, args.thr1, args.thr2)\n",
    "        print(f\"Val | {target_label} | fold {fold} | F1_macro={f1:.4f} Acc={acc:.4f} | preds 0:{counts[0]} 1:{counts[1]} 2:{counts[2]}\")\n",
    "        sched.step(f1)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            save_path = os.path.join(out_dir, \"best.pt\")\n",
    "            torch.save({\"state_dict\": model.state_dict(),\n",
    "                        \"epoch\": epoch,\n",
    "                        \"best_f1\": best_f1,\n",
    "                        \"mode\": args.mode,\n",
    "                        \"thr1\": args.thr1,\n",
    "                        \"thr2\": args.thr2}, save_path)\n",
    "            # print(f\"  -> saved {save_path}\")\n",
    "\n",
    "    return best_f1\n",
    "\n",
    "def train_all_labels(args):\n",
    "    set_seed(args.seed)\n",
    "    ensure_dir(args.out_dir)\n",
    "    device = args.device #\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    assert {\"filename\",\"patient_id\",\"path\",\"view\"}.issubset(df_train.columns)\n",
    "\n",
    "    df_folds = make_folds(df_train, n_splits=args.folds)\n",
    "    df_folds.to_csv(os.path.join(args.out_dir, \"df_folds.csv\"), index=False)\n",
    "\n",
    "    summary = {}\n",
    "    for lbl in LABELS:\n",
    "        bests = []\n",
    "        for fold in range(args.folds):\n",
    "            bests.append(train_one_fold_one_label(fold, lbl, df_folds, args, device))\n",
    "        summary[lbl] = {\"bests_per_fold\": bests, \"offcv_mean_f1\": float(np.mean(bests))}\n",
    "        print(f\"[{lbl}] OFF-CV F1_macro mean = {summary[lbl]['offcv_mean_f1']:.4f}\")\n",
    "\n",
    "    with open(os.path.join(args.out_dir, \"offcv_summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    return summary\n",
    "\n",
    "# =========================\n",
    "# 7) Inferencia en df_test por label\n",
    "#    Devuelve DataFrame con pred_*, (y opcionalmente probs/score01)\n",
    "# =========================\n",
    "def load_best_model_for_label(args, label_name, fold, device):\n",
    "    path = os.path.join(args.out_dir, label_name, f\"fold{fold}\", \"best.pt\")\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    model = Model3DResnetOne(in_channels=1, num_classes=3,\n",
    "                             pretrained=False, dropout_p=args.dropout,\n",
    "                             freeze_n=args.freeze_n, mode=ckpt.get(\"mode\", args.mode)).to(device)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    thr1 = ckpt.get(\"thr1\", args.thr1); thr2 = ckpt.get(\"thr2\", args.thr2)\n",
    "    return model, thr1, thr2\n",
    "\n",
    "def predict_df_test_one_label(args, df_test, label_name, fold_for_infer=0, return_probs=True):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, thr1, thr2 = load_best_model_for_label(args, label_name, fold_for_infer, device)\n",
    "\n",
    "    ds = MRIDataset3DOneTarget(df_test, target_label=label_name, is_train=False,\n",
    "                               use_aug=False, spatial_size=args.spatial_size)\n",
    "    dl = DataLoader(ds, batch_size=args.batch_size, shuffle=False,\n",
    "                    num_workers=args.num_workers, pin_memory=True)\n",
    "\n",
    "    recs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, _, fnames, view1h in tqdm(dl, desc=f\"Infer {label_name} (fold{fold_for_infer})\"):\n",
    "            imgs, view1h = imgs.to(device), view1h.to(device)\n",
    "            logits = model(imgs, view1h)\n",
    "            if model.mode == \"multiclass\":\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                pred = probs.argmax(-1)\n",
    "                # opcional \"score01\" heurístico (0*P0 + 0.5*P1 + 1*P2)\n",
    "                score01 = (probs[:,1]*0.5 + probs[:,2]*1.0).cpu().numpy()\n",
    "                for f, p, s, p0, p1, p2 in zip(fnames, pred.cpu().numpy(), score01,\n",
    "                                               probs[:,0].cpu().numpy(), probs[:,1].cpu().numpy(), probs[:,2].cpu().numpy()):\n",
    "                    recs.append({\"filename\": f,\n",
    "                                 f\"pred_{label_name}\": int(p),\n",
    "                                 f\"score01_{label_name}\": float(s),\n",
    "                                 f\"p0_{label_name}\": float(p0),\n",
    "                                 f\"p1_{label_name}\": float(p1),\n",
    "                                 f\"p2_{label_name}\": float(p2)})\n",
    "            else:\n",
    "                # ordinal: logits -> p_ge1, p_eq2; score01 = (p_ge1 + p_eq2)/2\n",
    "                pred, p_ge1, p_eq2 = ordinal_decode_one(logits, thr1=thr1, thr2=thr2)\n",
    "                score01 = ((p_ge1 + p_eq2)/2.0).cpu().numpy()\n",
    "                for f, p, s, a, b in zip(fnames, pred.cpu().numpy(), score01,\n",
    "                                         p_ge1.cpu().numpy(), p_eq2.cpu().numpy()):\n",
    "                    recs.append({\"filename\": f,\n",
    "                                 f\"pred_{label_name}\": int(p),\n",
    "                                 f\"score01_{label_name}\": float(s),\n",
    "                                 f\"p_ge1_{label_name}\": float(a),\n",
    "                                 f\"p_eq2_{label_name}\": float(b)})\n",
    "    return pd.DataFrame(recs)\n",
    "\n",
    "def predict_df_test_all_labels(args):\n",
    "    #df_test = pd.read_csv(args.test_csv)\n",
    "    assert {\"filename\",\"path\",\"view\"}.issubset(df_test.columns)\n",
    "    dfs = []\n",
    "    for lbl in LABELS:\n",
    "        df_lbl = predict_df_test_one_label(args, df_test, lbl, fold_for_infer=0)\n",
    "        dfs.append(df_lbl)\n",
    "    # merge por filename\n",
    "    out = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        out = out.merge(dfs[i], on=\"filename\", how=\"outer\")\n",
    "    out_path = os.path.join(args.out_dir, \"preds_test.csv\")\n",
    "    out.to_csv(out_path, index=False)\n",
    "    print(f\"[OK] guardado: {out_path}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21524b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[Noise] Fold 0 Epoch 0: 100%|██████████| 212/212 [00:15<00:00, 13.26it/s, loss=0.3674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.5936 Acc=0.8962 | preds 0:100 1:0 2:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 1: 100%|██████████| 212/212 [00:15<00:00, 13.43it/s, loss=0.3157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.5618 Acc=0.8774 | preds 0:96 1:0 2:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 2: 100%|██████████| 212/212 [00:15<00:00, 13.45it/s, loss=0.2943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.5703 Acc=0.8868 | preds 0:99 1:0 2:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 3: 100%|██████████| 212/212 [00:15<00:00, 13.66it/s, loss=0.2422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.6170 Acc=0.8868 | preds 0:99 1:2 2:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 4: 100%|██████████| 212/212 [00:15<00:00, 13.53it/s, loss=0.3048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.6233 Acc=0.8962 | preds 0:98 1:1 2:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 5: 100%|██████████| 212/212 [00:15<00:00, 13.51it/s, loss=0.2639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.6770 Acc=0.8962 | preds 0:97 1:2 2:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 6: 100%|██████████| 212/212 [00:15<00:00, 13.56it/s, loss=0.2639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.6171 Acc=0.8774 | preds 0:94 1:2 2:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 0 Epoch 7: 100%|██████████| 212/212 [00:15<00:00, 13.49it/s, loss=0.2506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 0 | F1_macro=0.6491 Acc=0.9057 | preds 0:100 1:0 2:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[Noise] Fold 1 Epoch 0: 100%|██████████| 212/212 [00:15<00:00, 13.47it/s, loss=0.3726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.4890 Acc=0.8585 | preds 0:103 1:0 2:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 1: 100%|██████████| 212/212 [00:15<00:00, 13.41it/s, loss=0.2821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.4906 Acc=0.8585 | preds 0:102 1:1 2:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 2: 100%|██████████| 212/212 [00:16<00:00, 13.23it/s, loss=0.2830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.5849 Acc=0.8396 | preds 0:95 1:5 2:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 3: 100%|██████████| 212/212 [00:16<00:00, 13.04it/s, loss=0.2998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.4576 Acc=0.7925 | preds 0:85 1:0 2:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 4: 100%|██████████| 212/212 [00:16<00:00, 13.23it/s, loss=0.3093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.5649 Acc=0.8679 | preds 0:100 1:1 2:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 5: 100%|██████████| 212/212 [00:16<00:00, 13.05it/s, loss=0.2399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.5120 Acc=0.8585 | preds 0:101 1:0 2:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 6: 100%|██████████| 212/212 [00:16<00:00, 13.22it/s, loss=0.2481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.5668 Acc=0.8774 | preds 0:101 1:0 2:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 1 Epoch 7: 100%|██████████| 212/212 [00:16<00:00, 13.11it/s, loss=0.2647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 1 | F1_macro=0.5975 Acc=0.8774 | preds 0:98 1:2 2:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[Noise] Fold 2 Epoch 0: 100%|██████████| 212/212 [00:16<00:00, 12.92it/s, loss=0.3444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.4403 Acc=0.8113 | preds 0:103 1:0 2:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 1: 100%|██████████| 212/212 [00:16<00:00, 12.98it/s, loss=0.3448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.3793 Acc=0.7358 | preds 0:93 1:3 2:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 2: 100%|██████████| 212/212 [00:16<00:00, 13.00it/s, loss=0.2737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.6005 Acc=0.8679 | preds 0:93 1:1 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 3: 100%|██████████| 212/212 [00:16<00:00, 12.96it/s, loss=0.2393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.5530 Acc=0.7925 | preds 0:78 1:5 2:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 4: 100%|██████████| 212/212 [00:16<00:00, 13.25it/s, loss=0.2551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.5758 Acc=0.8491 | preds 0:96 1:3 2:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 5: 100%|██████████| 212/212 [00:16<00:00, 13.18it/s, loss=0.3050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.5668 Acc=0.8585 | preds 0:91 1:0 2:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 6: 100%|██████████| 212/212 [00:16<00:00, 13.05it/s, loss=0.2888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.5735 Acc=0.8679 | preds 0:94 1:0 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 2 Epoch 7: 100%|██████████| 212/212 [00:16<00:00, 12.80it/s, loss=0.2303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 2 | F1_macro=0.5837 Acc=0.8679 | preds 0:90 1:0 2:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[Noise] Fold 3 Epoch 0: 100%|██████████| 212/212 [00:16<00:00, 12.82it/s, loss=0.3211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.5194 Acc=0.8019 | preds 0:97 1:0 2:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 1: 100%|██████████| 212/212 [00:16<00:00, 12.72it/s, loss=0.2962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.3810 Acc=0.7547 | preds 0:104 1:0 2:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 2: 100%|██████████| 212/212 [00:16<00:00, 12.93it/s, loss=0.2633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.5305 Acc=0.8019 | preds 0:97 1:1 2:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 3: 100%|██████████| 212/212 [00:17<00:00, 12.28it/s, loss=0.2474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.5614 Acc=0.8208 | preds 0:95 1:0 2:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 4: 100%|██████████| 212/212 [00:16<00:00, 13.20it/s, loss=0.2448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.4058 Acc=0.7642 | preds 0:95 1:4 2:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 5: 100%|██████████| 212/212 [00:16<00:00, 12.71it/s, loss=0.2472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.5490 Acc=0.8019 | preds 0:96 1:1 2:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 6: 100%|██████████| 212/212 [00:16<00:00, 12.96it/s, loss=0.2174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.5523 Acc=0.8208 | preds 0:94 1:0 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 3 Epoch 7: 100%|██████████| 212/212 [00:16<00:00, 12.99it/s, loss=0.2102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 3 | F1_macro=0.4933 Acc=0.7830 | preds 0:97 1:1 2:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[Noise] Fold 4 Epoch 0: 100%|██████████| 212/212 [00:16<00:00, 13.13it/s, loss=0.3293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5643 Acc=0.8476 | preds 0:89 1:4 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 1: 100%|██████████| 212/212 [00:16<00:00, 13.03it/s, loss=0.2985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5646 Acc=0.8571 | preds 0:91 1:2 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 2: 100%|██████████| 212/212 [00:15<00:00, 13.47it/s, loss=0.2682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5813 Acc=0.8762 | preds 0:93 1:1 2:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 3: 100%|██████████| 212/212 [00:15<00:00, 13.36it/s, loss=0.2823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5443 Acc=0.8571 | preds 0:90 1:1 2:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 4: 100%|██████████| 212/212 [00:16<00:00, 12.70it/s, loss=0.2454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5793 Acc=0.8667 | preds 0:92 1:2 2:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 5: 100%|██████████| 212/212 [00:16<00:00, 12.90it/s, loss=0.2520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.6001 Acc=0.8762 | preds 0:91 1:2 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 6: 100%|██████████| 212/212 [00:16<00:00, 12.66it/s, loss=0.2406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.6021 Acc=0.8857 | preds 0:92 1:1 2:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Noise] Fold 4 Epoch 7: 100%|██████████| 212/212 [00:15<00:00, 13.31it/s, loss=0.2768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val | Noise | fold 4 | F1_macro=0.5909 Acc=0.8857 | preds 0:91 1:1 2:13\n",
      "[Noise] OFF-CV F1_macro mean = 0.6077\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src import utils\n",
    "from src.dataset3D import MRIDataset3D\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "utils.set_seed(42)\n",
    "\n",
    "results_dir = '../../results/preprocessed_data/'\n",
    "\n",
    "#labels=[\"Noise\", \"Zipper\", \"Positioning\", \"Banding\", \"Motion\", \"Contrast\", \"Distortion\"]\n",
    "LABELS = [\"Noise\"]#,\"Zipper\",\"Positioning\",\"Banding\",\"Motion\",\"Contrast\",\"Distortion\"]\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(results_dir, 'df_train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(results_dir, 'df_test.csv'))\n",
    "df_train[\"patient_id\"] = df_train[\"filename\"].str.extract(r\"(LISA_\\d+)\")\n",
    "df_test[\"patient_id\"]  = df_test[\"filename\"].str.extract(r\"(LISA_VALIDATION_\\d+)\")\n",
    "    \n",
    "df_train.head(2)\n",
    "\n",
    "args = Args(\n",
    "    train_csv=\"/ruta/a/df_train.csv\",\n",
    "    test_csv =\"/ruta/a/df_test.csv\",\n",
    "    out_dir  =\"./runs_nb_5fold_ord_perlabel\",\n",
    "    folds=5, epochs=8, batch_size=2, num_workers=2,\n",
    "    lr=3e-4, wd=1e-4, dropout=0.3, freeze_n=2,\n",
    "    spatial_size=(40,120,120),\n",
    "    use_aug=True, seed=42, amp=True,\n",
    "    mode=\"ordinal\",   # prueba ordinal primero\n",
    "    thr1=0.55,        # puedes tunear estos thresholds\n",
    "    thr2=0.45,\n",
    "    device=\"cuda:5\"\n",
    ")\n",
    "\n",
    "summary = train_all_labels(args)   # entrena 7 modelos × 5 folds y guarda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b4a8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df_test_all_labels(args, strategy=\"mean\"):\n",
    "    \"\"\"\n",
    "    strategy: \"fold0\", \"best\", \"mean\", \"vote\"\n",
    "    \"\"\"\n",
    "    #df_test = pd.read_csv(args.test_csv)\n",
    "    assert {\"filename\",\"path\",\"view\"}.issubset(df_test.columns)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dfs_out = []\n",
    "\n",
    "    for lbl in LABELS:\n",
    "        print(f\"[Predict] Label={lbl} Strategy={strategy}\")\n",
    "        # Cargar folds y probs\n",
    "        probs_list, preds_list = [], []\n",
    "        thr1, thr2 = args.thr1, args.thr2\n",
    "        for fold in range(args.folds):\n",
    "            model, t1, t2 = load_best_model_for_label(args, lbl, fold, device)\n",
    "            thr1, thr2 = t1, t2\n",
    "            ds = MRIDataset3DOneTarget(df_test, target_label=lbl, is_train=False,\n",
    "                                       use_aug=False, spatial_size=args.spatial_size)\n",
    "            dl = DataLoader(ds, batch_size=args.batch_size, shuffle=False,\n",
    "                            num_workers=args.num_workers, pin_memory=True)\n",
    "            fold_probs, fold_preds = [], []\n",
    "            with torch.no_grad():\n",
    "                for imgs, _, fnames, view1h in dl:\n",
    "                    imgs, view1h = imgs.to(device), view1h.to(device)\n",
    "                    logits = model(imgs, view1h)\n",
    "                    if model.mode == \"multiclass\":\n",
    "                        p = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "                        fold_probs.append(p)\n",
    "                        fold_preds.append(p.argmax(-1))\n",
    "                    else:\n",
    "                        pred, p_ge1, p_eq2 = ordinal_decode_one(logits, thr1, thr2)\n",
    "                        # prob vector similar a multiclass: [P0, P1, P2]\n",
    "                        p0 = 1 - p_ge1\n",
    "                        p1 = p_ge1 - p_eq2\n",
    "                        p2 = p_eq2\n",
    "                        p = torch.stack([p0, p1, p2], dim=1).cpu().numpy()\n",
    "                        fold_probs.append(p)\n",
    "                        fold_preds.append(pred.cpu().numpy())\n",
    "            probs_list.append(np.concatenate(fold_probs, axis=0))\n",
    "            preds_list.append(np.concatenate(fold_preds, axis=0))\n",
    "\n",
    "        # Estrategias\n",
    "        if strategy == \"fold0\":\n",
    "            final_probs = probs_list[0]\n",
    "            final_preds = preds_list[0]\n",
    "        elif strategy == \"best\":\n",
    "            # cargar resumen de f1\n",
    "            summary_path = os.path.join(args.out_dir, \"offcv_summary.json\")\n",
    "            if not os.path.exists(summary_path):\n",
    "                raise FileNotFoundError(\"No summary encontrado para estrategia 'best'\")\n",
    "            import json\n",
    "            with open(summary_path) as f:\n",
    "                summary = json.load(f)\n",
    "            best_fold = int(np.argmax(summary[lbl][\"bests_per_fold\"]))\n",
    "            final_probs = probs_list[best_fold]\n",
    "            final_preds = preds_list[best_fold]\n",
    "        elif strategy == \"mean\":\n",
    "            final_probs = np.mean(probs_list, axis=0)\n",
    "            final_preds = np.argmax(final_probs, axis=-1)\n",
    "        elif strategy == \"vote\":\n",
    "            stacked_preds = np.stack(preds_list, axis=0)  # (folds, N)\n",
    "            from scipy.stats import mode\n",
    "            final_preds, _ = mode(stacked_preds, axis=0, keepdims=False)\n",
    "            final_probs = np.mean(probs_list, axis=0)\n",
    "        else:\n",
    "            raise ValueError(f\"Estrategia '{strategy}' no soportada\")\n",
    "\n",
    "        # Crear DF por label\n",
    "        df_lbl = pd.DataFrame({\n",
    "            \"filename\": df_test[\"filename\"],\n",
    "            f\"pred_{lbl}\": final_preds,\n",
    "            f\"p0_{lbl}\": final_probs[:,0],\n",
    "            f\"p1_{lbl}\": final_probs[:,1],\n",
    "            f\"p2_{lbl}\": final_probs[:,2],\n",
    "            f\"score01_{lbl}\": final_probs[:,1]*0.5 + final_probs[:,2]\n",
    "        })\n",
    "        dfs_out.append(df_lbl)\n",
    "\n",
    "    # Merge final\n",
    "    df_final = dfs_out[0]\n",
    "    for i in range(1, len(dfs_out)):\n",
    "        df_final = df_final.merge(dfs_out[i], on=\"filename\", how=\"outer\")\n",
    "\n",
    "    out_path = os.path.join(args.out_dir, f\"preds_test_{strategy}.csv\")\n",
    "    df_final.to_csv(out_path, index=False)\n",
    "    print(f\"[OK] Guardado en {out_path}\")\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14eb8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predict] Label=Noise Strategy=fold0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/va0831/env_cris/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Guardado en ./runs_nb_5fold_ord_perlabel/preds_test_fold0.csv\n",
      "[Predict] Label=Noise Strategy=best\n",
      "[OK] Guardado en ./runs_nb_5fold_ord_perlabel/preds_test_best.csv\n",
      "[Predict] Label=Noise Strategy=mean\n",
      "[OK] Guardado en ./runs_nb_5fold_ord_perlabel/preds_test_mean.csv\n",
      "[Predict] Label=Noise Strategy=vote\n",
      "[OK] Guardado en ./runs_nb_5fold_ord_perlabel/preds_test_vote.csv\n"
     ]
    }
   ],
   "source": [
    "# Fold 0 solo\n",
    "preds_fold0 = predict_df_test_all_labels(args, strategy=\"fold0\")\n",
    "\n",
    "# Mejor fold por label (según F1 en entrenamiento)\n",
    "preds_best = predict_df_test_all_labels(args, strategy=\"best\")\n",
    "\n",
    "# Promedio de probabilidades de todos los folds (recomendado)\n",
    "preds_mean = predict_df_test_all_labels(args, strategy=\"mean\")\n",
    "\n",
    "# Votación mayoritaria de folds\n",
    "preds_vote = predict_df_test_all_labels(args, strategy=\"vote\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf906a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
