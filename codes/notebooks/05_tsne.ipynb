{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8882c1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Zipper</th>\n",
       "      <th>Positioning</th>\n",
       "      <th>Banding</th>\n",
       "      <th>Motion</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Distortion</th>\n",
       "      <th>path</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>dim_x</th>\n",
       "      <th>dim_y</th>\n",
       "      <th>dim_z</th>\n",
       "      <th>spacing_x</th>\n",
       "      <th>spacing_y</th>\n",
       "      <th>spacing_z</th>\n",
       "      <th>view</th>\n",
       "      <th>img_path</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LISA_0001_LF_axi.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>LISA_0001</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>146</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>axi</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>0.014792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LISA_0001_LF_axi.nii.gz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>LISA_0001</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>146</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>axi</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>/data/cristian/projects/med_data/rise-miccai/t...</td>\n",
       "      <td>0.014792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename  Noise  Zipper  Positioning  Banding  Motion  \\\n",
       "0  LISA_0001_LF_axi.nii.gz      0       0            0        0       0   \n",
       "1  LISA_0001_LF_axi.nii.gz      0       0            0        0       0   \n",
       "\n",
       "   Contrast  Distortion                                               path  \\\n",
       "0         0           0  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "1         0           0  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "\n",
       "  patient_id  dim_x  dim_y  dim_z  spacing_x  spacing_y  spacing_z view  \\\n",
       "0  LISA_0001     36    120    146        5.0        1.5        1.5  axi   \n",
       "1  LISA_0001     36    120    146        5.0        1.5        1.5  axi   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "1  /data/cristian/projects/med_data/rise-miccai/t...   \n",
       "\n",
       "                                            npy_path     ratio  \n",
       "0  /data/cristian/projects/med_data/rise-miccai/t...  0.014792  \n",
       "1  /data/cristian/projects/med_data/rise-miccai/t...  0.014792  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from src import utils\n",
    "from src.dataset2D import MRIDataset2D\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "utils.set_seed(42)\n",
    "\n",
    "results_dir = '../../results/preprocessed_data/'\n",
    "labels=[\"Noise\", \"Zipper\", \"Positioning\", \"Banding\", \"Motion\", \"Contrast\", \"Distortion\"]\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(results_dir, 'df_train_imgs.csv'))\n",
    "df_test = pd.read_csv(os.path.join(results_dir, 'df_test_imgs.csv'))\n",
    "df_train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec385fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"pixels distribution : saved as image\")\n",
    "plt.hist(plt.imread(df_train.loc[0,\"img_path\"]).flatten(), bins=50)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"pixels distribution : saved as npy\")\n",
    "plt.hist(np.load(df_train.loc[0,\"npy_path\"]).flatten(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bd895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open_clip_torch==2.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb854cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_embeddings_with_backbones.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, json, math, random, argparse\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "\n",
    "# extras\n",
    "import timm\n",
    "import open_clip\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "\n",
    "# ----------------------- Helpers básicos -----------------------\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "CLIP_MEAN     = [0.48145466, 0.4578275, 0.40821073]\n",
    "CLIP_STD      = [0.26862954, 0.26130258, 0.27577711]\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def ensure_dir(p: str): Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def robust_scale01(x: np.ndarray, p_low=1.0, p_high=99.0):\n",
    "    lo, hi = np.percentile(x, [p_low, p_high])\n",
    "    if hi <= lo: return np.clip((x - x.min()) / (x.ptp() + 1e-8), 0, 1)\n",
    "    return np.clip((x - lo) / (hi - lo), 0, 1).astype(np.float32)\n",
    "\n",
    "def load_slice(img_path: Optional[str], npy_path: Optional[str], prefer: str) -> np.ndarray:\n",
    "    if prefer == \"npy\" and npy_path and os.path.exists(npy_path):\n",
    "        arr = np.load(npy_path)\n",
    "        if arr.ndim == 3: arr = arr.squeeze()\n",
    "        return robust_scale01(arr.astype(np.float32))\n",
    "    if img_path and os.path.exists(img_path):\n",
    "        im = Image.open(img_path).convert(\"L\")\n",
    "        arr = np.array(im).astype(np.float32) / 255.0\n",
    "        return robust_scale01(arr)\n",
    "    raise FileNotFoundError(f\"Missing slice: {img_path} | {npy_path}\")\n",
    "\n",
    "# ----------------------- Backbones -----------------------\n",
    "class TimmBackbone(nn.Module):\n",
    "    \"\"\"Cualquier timm con num_classes=0 -> features directas.\"\"\"\n",
    "    def __init__(self, model_name: str, pretrained=True, in_chans=3):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=in_chans)\n",
    "        self.out_dim = self.model.num_features\n",
    "\n",
    "    def forward(self, x):  # (B,3,H,W)\n",
    "        return self.model(x)\n",
    "\n",
    "def get_visual_outdim(visual: nn.Module, device=\"cpu\", img_size=224):\n",
    "    # 1) atributos típicos\n",
    "    for attr in [\"output_dim\", \"embed_dim\", \"feature_dim\", \"num_features\"]:\n",
    "        if hasattr(visual, attr):\n",
    "            val = getattr(visual, attr)\n",
    "            if isinstance(val, (int, float)):\n",
    "                return int(val)\n",
    "    # 2) cabeza/proyección (open_clip timm visual)\n",
    "    head = getattr(visual, \"head\", None)\n",
    "    if head is not None:\n",
    "        proj = getattr(head, \"proj\", None)\n",
    "        if proj is not None and hasattr(proj, \"out_features\") and proj.out_features is not None:\n",
    "            return int(proj.out_features)\n",
    "        if hasattr(head, \"out_features\") and head.out_features is not None:\n",
    "            return int(head.out_features)\n",
    "    # 3) forward con dummy\n",
    "    with torch.no_grad():\n",
    "        x = torch.zeros(1, 3, img_size, img_size, device=device)\n",
    "        y = visual(x)\n",
    "        # y típicamente (1, D)\n",
    "        return int(y.shape[-1])\n",
    "\n",
    "\n",
    "def build_backbone(kind: str, device: str, rad_weights: Optional[str]=None):\n",
    "    \"\"\"\n",
    "    Devuelve: (net, preprocess_fn(Image)->Tensor3xHxW, out_dim, img_size, mean,std)\n",
    "    \"\"\"\n",
    "    # Defaults\n",
    "    img_size = 224\n",
    "    mean, std = IMAGENET_MEAN, IMAGENET_STD\n",
    "    preprocess_from_openclip = None\n",
    "\n",
    "    if kind == \"resnet18_imagenet\":\n",
    "        net = TimmBackbone(\"resnet18\", pretrained=True)\n",
    "        out_dim = net.out_dim\n",
    "\n",
    "    elif kind == \"dinov2_vitl14\":\n",
    "        net = TimmBackbone(\"vit_large_patch14_dinov2\", pretrained=True)\n",
    "        out_dim = net.out_dim\n",
    "\n",
    "    elif kind == \"clip_vitb16_openai\":\n",
    "        model, preprocess, _ = open_clip.create_model_and_transforms('ViT-B-16', pretrained='openai', device=device)\n",
    "        net = model.visual\n",
    "        out_dim = get_visual_outdim(net, device=device, img_size=224)  # <-- cambia aquí\n",
    "        preprocess_from_openclip = preprocess\n",
    "        mean, std = CLIP_MEAN, CLIP_STD\n",
    "\n",
    "    elif kind == \"biomedclip_hf\":\n",
    "        model, preprocess = open_clip.create_model_from_pretrained(\n",
    "            'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224',\n",
    "            cache_dir = \"/data/cristian/projects/med_data/rise-miccai/pretrained_models/\"\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        net = model.visual\n",
    "        out_dim = get_visual_outdim(net, device=device, img_size=224)  # <-- y aquí\n",
    "        preprocess_from_openclip = preprocess\n",
    "        mean, std = CLIP_MEAN, CLIP_STD\n",
    "\n",
    "\n",
    "    elif kind == \"radimagenet_densenet121\":\n",
    "        assert rad_weights is not None and os.path.exists(rad_weights), \\\n",
    "            \"Para radimagenet_densenet121 debes pasar --radimagenet_weights a un .pth válido\"\n",
    "        net = TimmBackbone(\"densenet121\", pretrained=False)\n",
    "        sd = torch.load(rad_weights, map_location=\"cpu\")\n",
    "        if isinstance(sd, dict) and \"state_dict\" in sd: sd = sd[\"state_dict\"]\n",
    "        net.load_state_dict(sd, strict=False)\n",
    "        out_dim = net.out_dim\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone no soportado: {kind}\")\n",
    "\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    # Preprocess wrappers\n",
    "    if preprocess_from_openclip is not None:\n",
    "        def preprocess_fn(img01: np.ndarray) -> torch.Tensor:\n",
    "            # open_clip preprocess espera PIL RGB\n",
    "            pil = Image.fromarray((img01*255).astype(np.uint8), mode=\"L\").convert(\"RGB\")\n",
    "            return preprocess_from_openclip(pil)  # (3,H,W)\n",
    "    else:\n",
    "        import torchvision.transforms as T\n",
    "        tfm = T.Compose([\n",
    "            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.BICUBIC),\n",
    "            T.ToTensor(),                          # (1,H,W)\n",
    "            T.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "            T.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "        def preprocess_fn(img01: np.ndarray) -> torch.Tensor:\n",
    "            pil = Image.fromarray((img01*255).astype(np.uint8), mode=\"L\")\n",
    "            return tfm(pil)\n",
    "\n",
    "    return net, preprocess_fn, out_dim, img_size, mean, std\n",
    "\n",
    "# ---------- NEW: agregación por filename ----------\n",
    "def aggregate_filename(\n",
    "    sub_df: pd.DataFrame,\n",
    "    feats: np.ndarray,\n",
    "    cat: str,\n",
    "    label_reduce: str = \"max\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Agrupa por filename y promedia embeddings. Reduce la etiqueta del cat:\n",
    "    - 'max'         -> severidad máxima (conservador)\n",
    "    - 'mean-round'  -> promedio y redondeo al entero más cercano\n",
    "    - 'majority'    -> voto mayoritario (desempate -> max)\n",
    "    Retorna:\n",
    "      agg_df: DataFrame colapsado por filename (1 fila por archivo)\n",
    "      agg_feats: embeddings promedio por filename\n",
    "      agg_labels: etiquetas agregadas por filename\n",
    "    \"\"\"\n",
    "    assert label_reduce in {\"max\", \"mean-round\", \"majority\"}\n",
    "    # Asegurar que tenemos columna filename\n",
    "    if \"filename\" not in sub_df.columns:\n",
    "        sub_df = sub_df.copy()\n",
    "        sub_df[\"filename\"] = sub_df[\"path\"].apply(os.path.basename)\n",
    "\n",
    "    # Concatenar para usar groupby sobre índices alineados\n",
    "    tmp = sub_df[[cat, \"patient_id\", \"filename\", \"view\"]].copy()\n",
    "    tmp[\"_row\"] = np.arange(len(tmp))\n",
    "\n",
    "    # índices por filename\n",
    "    groups = tmp.groupby(\"filename\")[\"_row\"].apply(list)\n",
    "\n",
    "    agg_rows = []\n",
    "    agg_feats = []\n",
    "    agg_labels = []\n",
    "\n",
    "    for fname, idxs in groups.items():\n",
    "        idxs = np.asarray(idxs, dtype=int)\n",
    "        f_mean = feats[idxs].mean(axis=0)            # promedio embeddings\n",
    "        # reducir etiqueta\n",
    "        labels = sub_df.loc[idxs, cat].astype(int).to_numpy()\n",
    "        if label_reduce == \"max\":\n",
    "            lab = int(labels.max())\n",
    "        elif label_reduce == \"mean-round\":\n",
    "            lab = int(np.rint(labels.mean()))\n",
    "        else:  # majority\n",
    "            vals, cnts = np.unique(labels, return_counts=True)\n",
    "            lab = int(vals[np.argmax(cnts)])\n",
    "            # desempate (raro): coge el más severo\n",
    "            if (cnts == cnts.max()).sum() > 1:\n",
    "                lab = int(vals.max())\n",
    "\n",
    "        # fila representativa (tomamos la primera)\n",
    "        row0 = sub_df.loc[idxs[0]].copy()\n",
    "        row0[\"filename\"] = fname\n",
    "        row0[cat] = lab\n",
    "        row0[\"n_slices_agg\"] = len(idxs)\n",
    "\n",
    "        agg_rows.append(row0)\n",
    "        agg_feats.append(f_mean)\n",
    "        agg_labels.append(lab)\n",
    "\n",
    "    agg_df = pd.DataFrame(agg_rows).reset_index(drop=True)\n",
    "    agg_feats = np.vstack(agg_feats).astype(np.float32)\n",
    "    agg_labels = np.asarray(agg_labels, dtype=int)\n",
    "    return agg_df, agg_feats, agg_labels\n",
    "\n",
    "\n",
    "# ----------------------- Métricas & t-SNE -----------------------\n",
    "def class_separability(features: np.ndarray, labels: np.ndarray):\n",
    "    overall = features.mean(axis=0, keepdims=True)\n",
    "    between = 0.0; within = 1e-12\n",
    "    for c in np.unique(labels):\n",
    "        Xc = features[labels==c]\n",
    "        if len(Xc) < 2: continue\n",
    "        mc = Xc.mean(axis=0, keepdims=True)\n",
    "        between += len(Xc)*np.sum((mc-overall)**2)\n",
    "        within  += np.sum((Xc-mc)**2)\n",
    "    return float(between/within)\n",
    "\n",
    "def nearest_centroid_confusability(features: np.ndarray, labels: np.ndarray):\n",
    "    classes = sorted(list(np.unique(labels)))\n",
    "    cents = {c:features[labels==c].mean(axis=0,keepdims=True) for c in classes}\n",
    "    dists = {c: pairwise_distances(features, cents[c])[:,0] for c in classes}\n",
    "    winners = np.argmin(np.stack([dists[c] for c in classes], axis=1), axis=1)\n",
    "    def rate(a,b):\n",
    "        return float(np.mean(winners[labels==a] == classes.index(b))) if a in classes and b in classes else np.nan\n",
    "    return rate(1,2), rate(2,1)\n",
    "\n",
    "def compute_tsne(X: np.ndarray, seed: int, n_iter=1000, perplexity=None):\n",
    "    Xs = StandardScaler().fit_transform(X)\n",
    "    if Xs.shape[1] > 50:\n",
    "        Xs = PCA(n_components=50, random_state=seed).fit_transform(Xs)\n",
    "    if perplexity is None:\n",
    "        N = Xs.shape[0]; perplexity = max(5, min(30, max(5, (N//3)-1)))\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=\"auto\",\n",
    "                init=\"pca\", n_iter=n_iter, random_state=seed, metric=\"euclidean\")\n",
    "    Z = tsne.fit_transform(Xs)\n",
    "    return Z, perplexity\n",
    "\n",
    "def detect_outliers(X: np.ndarray, contamination=0.03, seed=1337):\n",
    "    iso = IsolationForest(n_estimators=300, contamination=contamination, random_state=seed, n_jobs=-1)\n",
    "    iso.fit(X)\n",
    "    iso_score = -iso.decision_function(X)\n",
    "    iso_flag  = (iso.predict(X) == -1).astype(int)\n",
    "    lof = LocalOutlierFactor(n_neighbors=35, contamination=contamination, n_jobs=-1)\n",
    "    lof_flag = (lof.fit_predict(X) == -1).astype(int)\n",
    "    lof_score = -lof.negative_outlier_factor_\n",
    "    consensus = ((iso_flag + lof_flag) >= 1).astype(int)\n",
    "    score = (iso_score + lof_score)/2.0\n",
    "    return {\"iso_scores\":iso_score,\"iso_flags\":iso_flag,\n",
    "            \"lof_scores\":lof_score,\"lof_flags\":lof_flag,\n",
    "            \"consensus_flags\":consensus,\"consensus_scores\":score}\n",
    "\n",
    "# ----------------------- Sampling -----------------------\n",
    "def balanced_sample_indices(df: pd.DataFrame, category: str, max_per_class=1200,\n",
    "                            per_patient_max=10, use_patient_level=False, seed=1337):\n",
    "    rng = random.Random(seed)\n",
    "    idxs = []\n",
    "    for cls in [0,1,2]:\n",
    "        sub = df[df[category]==cls]\n",
    "        picked = []\n",
    "        for pid, grp in sub.groupby(\"patient_id\"):\n",
    "            gidx = grp.index.to_list()\n",
    "            rng.shuffle(gidx)\n",
    "            picked.extend(gidx[:per_patient_max])\n",
    "        if len(picked) > max_per_class:\n",
    "            picked = rng.sample(picked, max_per_class)\n",
    "        idxs.extend(picked)\n",
    "    rng.shuffle(idxs)\n",
    "    return np.array(idxs, dtype=int)\n",
    "\n",
    "\n",
    "# ----------------------- Pipeline -----------------------\n",
    "def run_pipeline(df: pd.DataFrame, args):\n",
    "    set_seed(args.seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ensure_dir(args.out_dir)\n",
    "\n",
    "    net, preprocess_fn, feat_dim, img_size, mean, std = build_backbone(\n",
    "        args.backbone, device=device, rad_weights=args.radimagenet_weights\n",
    "    )\n",
    "\n",
    "    # Info de config\n",
    "    with open(os.path.join(args.out_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            \"backbone\": args.backbone,\n",
    "            \"feat_dim\": feat_dim,\n",
    "            \"img_size\": img_size,\n",
    "            \"prefer_source\": args.prefer_source,\n",
    "            \"categories\": args.categories,\n",
    "            \"seed\": args.seed\n",
    "        }, f, indent=2)\n",
    "\n",
    "    for cat in args.categories:\n",
    "        print(f\"\\n=== {cat} ===\")\n",
    "        idxs = balanced_sample_indices(\n",
    "            df, cat, max_per_class=args.max_per_class,\n",
    "            per_patient_max=args.max_slices_per_patient,\n",
    "            use_patient_level=False, seed=args.seed\n",
    "        )\n",
    "        sub = df.loc[idxs].reset_index(drop=True)\n",
    "\n",
    "        paths = list(zip(sub.get(\"img_path\",[None]*len(sub)),\n",
    "                         sub.get(\"npy_path\",[None]*len(sub))))\n",
    "\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            batch_np = []\n",
    "            for i,(ip,npyp) in enumerate(paths, start=1):\n",
    "                arr = load_slice(ip, npyp, args.prefer_source)  # (H,W) [0,1]\n",
    "                batch_np.append(arr)\n",
    "                if len(batch_np)==args.batch_size or i==len(paths):\n",
    "                    xs = torch.stack([preprocess_fn(a) for a in batch_np], dim=0).to(device)\n",
    "                    f = net(xs).detach().cpu().numpy()\n",
    "                    feats.append(f)\n",
    "                    batch_np = []\n",
    "        feats = np.concatenate(feats, axis=0)  # (N, D)\n",
    "        labels = sub[cat].astype(int).to_numpy()\n",
    "        # ... después de calcular feats (N,D) y antes de métricas:\n",
    "        # feats = np.concatenate(feats, axis=0)\n",
    "        # labels = sub[cat].astype(int).to_numpy()\n",
    "\n",
    "        # NEW: agregación por filename\n",
    "        sub_agg, feats_agg, labels_agg = aggregate_filename(\n",
    "            sub_df=sub, feats=feats, cat=cat, label_reduce=\"max\"  # cambia a \"mean-round\" o \"majority\" si prefieres\n",
    "        )\n",
    "\n",
    "        # Reemplazamos sub/feats/labels por los agregados\n",
    "        sub = sub_agg\n",
    "        feats = feats_agg\n",
    "        labels = labels_agg\n",
    "\n",
    "        # ---- métricas, t-SNE y outliers ya con agregados ----\n",
    "        fisher = class_separability(feats, labels)\n",
    "        try:\n",
    "            silh = silhouette_score(StandardScaler().fit_transform(feats), labels)\n",
    "        except Exception:\n",
    "            silh = float(\"nan\")\n",
    "        conf12, conf21 = nearest_centroid_confusability(feats, labels)\n",
    "        Z, px = compute_tsne(feats, seed=args.seed, n_iter=args.tsne_iters, perplexity=args.tsne_perplexity)\n",
    "        out = detect_outliers(feats, contamination=args.contamination, seed=args.seed)\n",
    "\n",
    "        res = sub.copy()\n",
    "        res[\"tsne_x\"], res[\"tsne_y\"] = Z[:,0], Z[:,1]\n",
    "        res[\"anomaly_flag\"]  = out[\"consensus_flags\"]\n",
    "        res[\"anomaly_score\"] = out[\"consensus_scores\"]\n",
    "        res[\"iso_score\"]     = out[\"iso_scores\"]\n",
    "        res[\"lof_score\"]     = out[\"lof_scores\"]\n",
    "        res[\"category\"]      = cat\n",
    "        res[\"fisher_ratio\"]  = fisher\n",
    "        res[\"silhouette\"]    = silh\n",
    "        res[\"conf_1_to_2\"], res[\"conf_2_to_1\"] = conf12, conf21\n",
    "\n",
    "        csv_path = os.path.join(args.out_dir, f\"tsne_{cat}_{args.backbone}.csv\")\n",
    "        res.to_csv(csv_path, index=False)\n",
    "        print(\"CSV:\", csv_path)\n",
    "\n",
    "        topN = min(100, len(res)//10 if len(res)>=10 else len(res))\n",
    "        res.nlargest(topN, \"anomaly_score\").to_csv(\n",
    "            os.path.join(args.out_dir, f\"outliers_top{topN}_{cat}_{args.backbone}.csv\"), index=False\n",
    "        )\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(8,6))\n",
    "        for c in [0,1,2]:\n",
    "            m = (labels==c)\n",
    "            if m.sum()>0:\n",
    "                plt.scatter(Z[m,0], Z[m,1], s=8, alpha=0.6, label=f\"{cat}={c}\")\n",
    "        # centroides\n",
    "        for c in [0,1,2]:\n",
    "            m = (labels==c)\n",
    "            if m.sum()>0:\n",
    "                cx,cy = Z[m,:].mean(axis=0)\n",
    "                plt.scatter([cx],[cy], s=120, marker=\"X\", edgecolor=\"k\")\n",
    "                plt.text(cx,cy, f\"C{c}\", fontsize=10, ha=\"center\", va=\"center\")\n",
    "        # outliers\n",
    "        mo = (res[\"anomaly_flag\"].to_numpy()==1)\n",
    "        if mo.any():\n",
    "            plt.scatter(Z[mo,0], Z[mo,1], s=18, facecolors=\"none\", edgecolors=\"k\", linewidths=0.8, label=\"outlier\")\n",
    "\n",
    "        plt.title(f\"{cat} | {args.backbone}\\nFisher={fisher:.2f}  Silh={silh:.2f}  perp={px}\")\n",
    "        plt.legend(markerscale=2, fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(args.out_dir, f\"tsne_{cat}_{args.backbone}.png\")\n",
    "        plt.savefig(fig_path, dpi=170)\n",
    "        plt.close()\n",
    "        print(\"PNG:\", fig_path)\n",
    "\n",
    "        # por paciente\n",
    "        byp = res.groupby(\"patient_id\")[\"anomaly_flag\"].mean().sort_values(ascending=False)\n",
    "        plt.figure(figsize=(10,3))\n",
    "        plt.plot(np.arange(len(byp)), byp.values, marker=\".\")\n",
    "        plt.title(f\"Outlier rate por paciente – {cat} – {args.backbone}\")\n",
    "        plt.xlabel(\"pacientes ordenados\"); plt.ylabel(\"ratio outliers\")\n",
    "        plt.tight_layout()\n",
    "        pfig = os.path.join(args.out_dir, f\"outlier_rate_by_patient_{cat}_{args.backbone}.png\")\n",
    "        plt.savefig(pfig, dpi=170); plt.close()\n",
    "\n",
    "# ----------------------- CLI -----------------------\n",
    "def parse_args():\n",
    "    ap = argparse.ArgumentParser(description=\"t-SNE + Outliers para MRI slices con selector de backbone\")\n",
    "    ap.add_argument(\"--csv\", type=str, default=None, help=\"Ruta a df_train.csv (si no, usa variable df_train del entorno via exec)\")\n",
    "    ap.add_argument(\"--out_dir\", type=str, default=\"tsne_outputs\")\n",
    "    ap.add_argument(\"--prefer_source\", type=str, default=\"npy\", choices=[\"npy\",\"img\"])\n",
    "    ap.add_argument(\"--categories\", type=str, nargs=\"+\", default=[\"Positioning\",\"Contrast\",\"Banding\"])\n",
    "    ap.add_argument(\"--backbone\", type=str, default=\"biomedclip_hf\",\n",
    "                    choices=[\"resnet18_imagenet\",\"clip_vitb16_openai\",\"biomedclip_hf\",\"dinov2_vitl14\",\"radimagenet_densenet121\"])\n",
    "    ap.add_argument(\"--radimagenet_weights\", type=str, default=None, help=\"Ruta a pesos .pth si usas radimagenet_densenet121\")\n",
    "    ap.add_argument(\"--max_per_class\", type=int, default=1200)\n",
    "    ap.add_argument(\"--max_slices_per_patient\", type=int, default=10)\n",
    "    ap.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    ap.add_argument(\"--tsne_iters\", type=int, default=1000)\n",
    "    ap.add_argument(\"--tsne_perplexity\", type=float, default=None)\n",
    "    ap.add_argument(\"--contamination\", type=float, default=0.035)\n",
    "    ap.add_argument(\"--seed\", type=int, default=1337)\n",
    "    return ap.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5c1373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Positioning ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2556616/91623564.py:140: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil = Image.fromarray((img01*255).astype(np.uint8), mode=\"L\").convert(\"RGB\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: tsne_outputs/tsne_Positioning_biomedclip_hf.csv\n",
      "PNG: tsne_outputs/tsne_Positioning_biomedclip_hf.png\n",
      "\n",
      "=== Contrast ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2556616/91623564.py:140: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil = Image.fromarray((img01*255).astype(np.uint8), mode=\"L\").convert(\"RGB\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: tsne_outputs/tsne_Contrast_biomedclip_hf.csv\n",
      "PNG: tsne_outputs/tsne_Contrast_biomedclip_hf.png\n",
      "\n",
      "=== Banding ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2556616/91623564.py:140: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  pil = Image.fromarray((img01*255).astype(np.uint8), mode=\"L\").convert(\"RGB\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: tsne_outputs/tsne_Banding_biomedclip_hf.csv\n",
      "PNG: tsne_outputs/tsne_Banding_biomedclip_hf.png\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Ruta CSV o None si ya tienes df_train en memoria\n",
    "        self.csv = \"df_train.csv\"  # o None\n",
    "        self.out_dir = \"tsne_outputs\"\n",
    "\n",
    "        # Preferencia de fuente de imagen\n",
    "        self.prefer_source = \"img\"  # \"npy\" o \"img\"\n",
    "\n",
    "        # Categorías a procesar\n",
    "        self.categories = [\"Positioning\", \"Contrast\", \"Banding\"]\n",
    "\n",
    "        # Selector de backbone\n",
    "        self.backbone = \"biomedclip_hf\"  \n",
    "        # opciones: \"resnet18_imagenet\", \"clip_vitb16_openai\", \"biomedclip_hf\", \"dinov2_vitl14\", \"radimagenet_densenet121\"\n",
    "\n",
    "        # Ruta a pesos si usas RadImageNet\n",
    "        self.radimagenet_weights = None  # \"/ruta/radimagenet_densenet121.pth\"\n",
    "\n",
    "        # Sampling y batch\n",
    "        self.max_per_class = 1200\n",
    "        self.max_slices_per_patient = 10\n",
    "        self.batch_size = 128\n",
    "\n",
    "        # t-SNE\n",
    "        self.tsne_iters = 1000\n",
    "        self.tsne_perplexity = None  # None = adaptativo\n",
    "\n",
    "        # Detección de outliers\n",
    "        self.contamination = 0.035\n",
    "\n",
    "        # Reproducibilidad\n",
    "        self.seed = 1337\n",
    "\n",
    "\n",
    "# Crear instancia\n",
    "args = Args()\n",
    "\n",
    "# Si quieres cambiar algo rápido:\n",
    "args.backbone = \"biomedclip_hf\"#clip_vitb16_openai\"\n",
    "args.prefer_source = \"npy\"\n",
    "\n",
    "\n",
    "# saneo mínimo\n",
    "needed = [\"patient_id\",\"img_path\",\"npy_path\",\"path\"]\n",
    "for c in [\"Positioning\",\"Contrast\",\"Banding\"]:\n",
    "    if c not in df_train.columns: print(f\"[WARN] columna {c} no está en el CSV (ok si no la usarás)\")\n",
    "run_pipeline(df_train, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c0435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
